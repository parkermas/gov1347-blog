# Introduction and Model Recap

It's been a long semester, but we finally know the outcome of the 2020 presidential election. So how did my final prediction stack up against the actual results? To recap, I created a two-sided, unpooled ensemble model that predicted a separate vote share for both the Democratic and Republican candidate in each state. The predicted vote share for the Democratic or Republican candidate in each state was calculated based on the results of two equally weighted linear regressions, with the first regression using only polling data (using only polls conducted 2 weeks before the election or sooner) to predict vote share. The second regression used the vote share from the previous election, the change in the state's white population since the previous election, and whether or not the candidate's party has incumbency status to predict vote share. Ultimately, I predicted that Democrat Joe Biden would win **279** electoral votes to Republican Donald Trump's **259**, and the results of the actual election were not too far off, with Biden winning **306** electoral votes to Trump's **232**. Take a look below at the actual electoral vote totals versus my predicted totals:

  Actual EV Totals         |  Predicted EV Totals
:-------------------------:|:-------------------------:
![](actual_bargraph.jpeg)  |  ![](predicted_bargraph.jpeg)

In a winner-take-all system like the electoral college, where the winner of each state recieves all of its electoral votes (excluding Maine and Nebraska, the two states that can split their electoral votes), being able to predict the winner of each state is key to correctly predicting the winner of the presidency. Using my model, I was able to correctly predict the winner of every state besides for the states of Arizona and Georgia. Even though I predicted that Trump would win both Georgia and Arizona by a little over 6 percentage points, it looks like Biden will ultimately win both by less than one percentage point in each state. While it is probably fair to say that my model did a pretty good job predicting the winner in each state and even successfully predicted that Joe Biden would win the presidential election, it's worth investigating the error in my prediction and any trends within the logic of my model that contributed to incorrect predictions in Georgia and Florida in order to understand how to create a stronger model for future elections. 

  Actual Map         |  Predicted Map
:-------------------------:|:-------------------------:
![](actual_outcome.jpeg)  |  ![](predicted_outcome.jpeg)

# Model Error 

Because I used a two-sided model that produced a separate Democratic and Republican vote share prediction for each state, I decided to plot the error in my predictions in each state for both parties in order to better understand any clear trends in the error.

  Democratic Error        |  Republican Error
:-------------------------:|:-------------------------:
![](dem_error.jpeg)  |  ![](rep_error.jpeg)

After considering these maps side-by-side, there are definitely some visually apparent trends in the error that are worth discussing. For starters, it seems as though the Republican vote share predictions were, on average, slightly more correct than the Democratic vote share predictions. However, it doesn't seem to be a very significant difference, and it's unlikely that a slight imbalance in the accuracy of the Democratic and Republican predictions was a major source of error in the model. Additionally, the states with the greatest and least error seem to be the same for both the Democratic and Republican predictions. Both New York and Oregon seem to be the states with the greatest error for both parties, and Washington state seems to be the state with the least error. It's also worth noting that it appears as though the average error in [battleground states](https://www.nytimes.com/interactive/2020/us/elections/electoral-college-battleground-states.html) is lower than the average error in non-battleground states for both Democratic and Republican predicted vote shares. Because of the historical trend of very small win margins in these states, this is a very good thing for my model, as these states ultimately ended up deciding the outcome of the election and thus accuracy in predicting them is key.


![](mean_errors.png)

The table helps to precisely quantify many of the trends apparent in the map. On average, the predicted Republican vote shares were a little more accurate, but only by less than half a percentage point. Additionally, error was universally lower for the predicted vote shares in battleground states, but still only by less than a percentage point as compared to non-battleground states. Relatively speaking, there are very few states overall that will have margins of victory that are less than 2 percentage points (basically all are battleground states), but based on the maps and this table it seems as though focusing on those states will tell me the most about where my model went wrong and why.

# What Happened? 

While it is clear that my model was successful in many important ways (predicting the overall winner, predicting the correct winner in 48/50 states, having relatively low error in predicting the Democratic and Republican vote shares in each state), the incorrect predictions for the states of Arizona and Georgia merit careful examination of my model's flaws. First, let's take a look at my predicted vote shares for battleground states alongside the actual vote shares for both candidates (note that state where the outcomes were correctly predicted are in green, and incorrect predictions are in red):

![](actual_predicted_margins.png)

Based on this table, where the states are listed in ascending order based on the total error of the predicted Democratic vote share in each state. Notably, Georgia and Arizona are two of the three states with the highest total error, the other one being the state of Iowa. However, the nature of the error for the Iowa predictions is quite different, as I had predicted that Biden would do much better in the state than he did. In the case of the Arizona and Georgia predictions, I predicted that Biden would do much worse than he actually did. Basically, from the perpsective of my predictions, Biden overperformed in Arizona and Georgia, and my model was not able to predict this (his underperformance in Iowa would be a bigger problem if my model had predicted him to win, but both my prediction and the actual outcome resulted in a Biden loss in the state). But this begs the question: why was my model unable to predict Biden victories in Arizona and Georgia, and what about those states (as compared to other battleground states) made them different from other states that largely followed historical trends in ultimately going for either the Democratic or Republican candidate?

The first element in this puzzle has to do with a shift in the voting behavior of important demographic subgroups in the states of Arizona and Georgia that I was not able to meaningfully capture in my model. One of the big reasons why a Democratic presidential candidate was able to win in traditionally Republican states like Arizona and Georgia is due to a massive shift in [white, college-educated voters who supported Trump in 2016 but voted for Biden in 2020](https://www.brookings.edu/research/2020-exit-polls-show-a-scrambling-of-democrats-and-republicans-traditional-bases/). College-educated white men in Georgia supported Trump over Biden by a margin of 55 points in 2016, but only supported Trump over Biden by a 12-point margin in 2020, marking a 43 percentage point shift from Trump to Biden. In Arizona, a similar dynamic is at play, with 17 and 15 point shifts towards Biden among college-educated white women and men, respectively. Additionally, the margin of support for Trump over Biden among non-college-educated white men in Arizona shrank by 18 points, which is also a fairly large drop in support among one of his key voting blocs. While my model did try to account for demographic change in each state, there was no way to really capture fairly marked shifts in support for candidates amongst particular demographic subgroups. It's also worth noting that these shifts in support from Trump to Biden amongst subgroups of white voters also occurred in other swing states I correctly predicted (such as Wisconsin, Pennsylvania, and Michigan), but the [historical trend of relatively larger support for Democrats amongst white voters in those states](https://prospect.org/power/michigan-pennsylvania-wisconsin-understanding-key-demographic-differences/) makes those trends less consequential for changing the outcomes in those states. 

The other issue that merits discussion is the role of particular minority demographic groups in powering the Democratic wins in Arizona and Georgia. In Arizona, it seems as though [support for Biden amongst hispanic voters](https://www.vox.com/21549607/latino-hispanic-vote-2020-trump-biden-arizona-florida) was key to his slim victory over Trump, and [Black voters in Georgia](https://apnews.com/article/election-2020-joe-biden-race-and-ethnicity-virus-outbreak-georgia-7a843bbce00713cfde6c3fdbc2e31eb7) were a huge factor in his ability to flip the state blue after decades of Republican victories and an [extremely slim Republican victory in the 2018 gubernatorial election](https://en.wikipedia.org/wiki/2018_Georgia_gubernatorial_election). Though I did use a predictive variable that represented the change in a state's white population (and inherently, the change in the state's nonwhite population) in my model, this did not account for changes in specific populations (hispanic & Black populations) that were uniquely important in each state's respective outcome. Below, see a table that shows the change in the Black, hispanic, and white populations in key battleground states.

![](demog_change.png)

As you can see, Georgia and Arizona had the largest increases in their Black populations, and Arizona had the second-largest increase in its hispanic population after Florida. This seems to suggest that including these variables in some way would have increased the predictive accuracy of my model, but it's also important to consider the fallacy of constructing a demographic category like "hispanic" and expecting it to be equally predictive across states. As we saw in this election, [hispanic voters do not vote as a monolith](https://www.wsj.com/articles/latino-voters-drifted-from-democrats-in-florida-and-texas-11604582691), and hispanic voters in Florida are very different than hispanic voters in Arizona and probably shouldn't be grouped together under the same category. 
Also notice how Georgia and Florida also had the biggest **decreases** in the white population (and polling right before the election showed narrow Biden leads in both states), but the states ultimately yielded very different outcomes in terms of of which candidate won the election, possibly suggesting that shifts in the white population alone were not quite as predictive as I had initally hoped they would be. This also ties back to my earlier point about shifts in support within  white population subgroups in Georgia and Arizona, which wouldn't be captured based on the change of the white population as a percentage of the overall population. Finally, it's important to note that the demographic breakdown of a state's population is probably less meaningful than the demographic breakdown of a state's **registered voters**. In Georgia, efforts by [grassroots groups to register voters](https://www.reuters.com/article/usa-election-georgia/how-stacey-abrams-paved-the-way-for-a-democratic-victory-in-new-georgia-idUSKBN27P197) seem to have paid dividends for Democrats, and similar work to [organize and register Latino voters in Arizona](https://www.theguardian.com/us-news/2020/oct/28/latino-voters-maricopa-county-phoenix-us-election) was a key factor in Biden's win in that state. 

In order to test my theory, 

